{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51c5d5e-a410-4b82-8605-8e761ed738b7",
   "metadata": {},
   "source": [
    "# Network Correlation and Covariance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f07699-5203-484d-8f00-dad3ed6f864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIP\n",
      "0\n",
      "Found Euclidean Distances\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Networks/HIP/HIP/HIP_01_delaunay_edgelist.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m netYsRes \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(measDists))]\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topoNum \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numTopos):\n\u001b[1;32m--> 134\u001b[0m     res \u001b[38;5;241m=\u001b[39m getResults(topoNum)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(measDists)):\n\u001b[0;32m    136\u001b[0m         eucSumRes[m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m][m]\n",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m, in \u001b[0;36mgetResults\u001b[1;34m(topoNum)\u001b[0m\n\u001b[0;32m     54\u001b[0m eucDistArr \u001b[38;5;241m=\u001b[39m spd\u001b[38;5;241m.\u001b[39msquareform(spd\u001b[38;5;241m.\u001b[39mpdist(coords,distanceWBoundary))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound Euclidean Distances\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mread_edgelist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNetworks/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mnetDict[netNum]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mnetDict[netNum]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mnetDict[netNum]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mnum\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mnetType\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_edgelist.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, nodetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m, data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mfloat\u001b[39m)])\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(netNum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39medges():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\networkx\\utils\\decorators.py:789\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 6:3\u001b[0m, in \u001b[0;36margmap_read_edgelist_1\u001b[1;34m(path, comments, delimiter, create_using, nodetype, data, edgetype, encoding, backend, **backend_kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\networkx\\utils\\decorators.py:199\u001b[0m, in \u001b[0;36mopen_file.<locals>._open_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# could be None, or a file handle, in which case the algorithm will deal with it\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m fobj \u001b[38;5;241m=\u001b[39m _dispatch_dict[ext](path, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fobj, \u001b[38;5;28;01mlambda\u001b[39;00m: fobj\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Networks/HIP/HIP/HIP_01_delaunay_edgelist.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import scipy.spatial.distance as spd\n",
    "import networkx as nx\n",
    "\n",
    "def distance(x1, y1, x2, y2):\n",
    "    return ((x2-x1)**2+(y2-y1)**2)**(1/2)\n",
    "\n",
    "def distanceWBoundary(p1,p2):\n",
    "    x1,y1 = p1\n",
    "    x2,y2 = p2\n",
    "    dists = []\n",
    "    dists.append(distance(x1,y1,x2,y2))\n",
    "    dists.append(distance(x1,y1,x2-1,y2))\n",
    "    dists.append(distance(x1,y1,x2+1,y2))\n",
    "    dists.append(distance(x1,y1,x2,y2-1))\n",
    "    dists.append(distance(x1,y1,x2,y2+1))\n",
    "    dists.append(distance(x1,y1,x2-1,y2-1))\n",
    "    dists.append(distance(x1,y1,x2-1,y2+1))\n",
    "    dists.append(distance(x1,y1,x2+1,y2-1))\n",
    "    dists.append(distance(x1,y1,x2+1,y2+1))\n",
    "    return min(dists)\n",
    "\n",
    "def getResults(topoNum):\n",
    "    eucSumArr = []\n",
    "    netSumArr = []\n",
    "    eucXsArr = []\n",
    "    eucYsArr = []\n",
    "    netXsArr = []\n",
    "    netYsArr = []\n",
    "    \n",
    "    if(netNum == 6 and topoNum == 4):\n",
    "        return\n",
    "    print(topoNum)\n",
    "    num = \"%02d\"%(topoNum+1)\n",
    "    \n",
    "    #Load Point Patterns and save into pointDict\n",
    "    f = open(\"Networks/\"+netDict[netNum]+'-'+num+'.txt','r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    if(netNum == 6):\n",
    "        if(topoNum == 0):\n",
    "            coords = np.array([x.rstrip().split('\\t') for x in lines if x.rstrip().split(' ') != ['']]).astype(float)\n",
    "        else:\n",
    "            coords = [(float(x.lstrip().rstrip().split(' ')[0]),float(x.lstrip().rstrip().split(' ')[-1])) for x in lines if x.rstrip().split(' ') != ['']]\n",
    "    else:\n",
    "        coords = np.array([x.rstrip().split('\\t') for x in lines if x.rstrip().split(' ') != ['']]).astype(float)\n",
    "    \n",
    "    if(netNum > 2):\n",
    "        coords = coords/100\n",
    "        \n",
    "    #Calculate Euclidean distances between all pairs of points\n",
    "    eucDistArr = spd.squareform(spd.pdist(coords,distanceWBoundary))\n",
    "    print(\"Found Euclidean Distances\")\n",
    "\n",
    "    G = nx.read_edgelist(\"Networks/\"+netDict[netNum]+'_'+num+'_'+netType.lower()+'_edgelist.txt', nodetype = int, data = [('distance',float)])\n",
    "    if(netNum > 2):\n",
    "        for edge in G.edges():\n",
    "            G.edges()[edge]['distance']/=100\n",
    "    G = G.subgraph(max(list(nx.connected_components(G)),key = len))\n",
    "    nodes = list(G.nodes())\n",
    "    distDict = dict(nx.all_pairs_dijkstra_path_length(G,weight = 'distance'))\n",
    "    distArr = np.zeros((len(nodes),len(nodes)))\n",
    "    #eucDistArr = np.zeros((len(G),len(G)))\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i):\n",
    "            if(i in distDict[j]):\n",
    "                distArr[i][j] = distDict[i][j]\n",
    "                distArr[j][i] = distDict[j][i]\n",
    "            else:\n",
    "                distArr[i][j] = np.inf\n",
    "                distArr[j][i] = np.inf\n",
    "    del distDict\n",
    "\n",
    "    #Save Densities/Co-densities\n",
    "    dist = 0.1\n",
    "    for measDist in measDists:\n",
    "        print(measDist)\n",
    "        eucSumArr.append(list(np.sum(eucDistArr<=measDist,axis=0)))\n",
    "        netSumArr.append(list(np.sum(distArr<=measDist,axis=0)))\n",
    "        \n",
    "    for m in range(len(measDists)-1):    \n",
    "        print(np.round(measDists[m],decimals=3))\n",
    "        nodePairs = (eucDistArr >= measDists[m]) & (eucDistArr <= measDists[m+1])\n",
    "        nodePairsNet = (distArr >= measDists[m]) & (distArr <= measDists[m+1])\n",
    "        eucDists = np.sum(eucDistArr<=dist,axis=0)\n",
    "        dists = np.sum(distArr<=dist,axis=0)\n",
    "        xs = []\n",
    "        ys = []\n",
    "        xsNet = []\n",
    "        ysNet = []\n",
    "        for i in range(len(nodes)):\n",
    "            densities = list(eucDists[nodePairs[i]])\n",
    "            xs += [eucDists[i]]*len(densities)\n",
    "            ys += densities\n",
    "            densitiesNet = list(dists[nodePairsNet[i]]) \n",
    "            xsNet += [dists[i]]*len(densitiesNet)\n",
    "            ysNet += densitiesNet\n",
    "                \n",
    "        eucXsArr.append(xs)\n",
    "        eucYsArr.append(ys)\n",
    "        netXsArr.append(xsNet)\n",
    "        netYsArr.append(ysNet)\n",
    "            \n",
    "    return eucSumArr,netSumArr,eucXsArr,eucYsArr,netXsArr,netYsArr\n",
    "\n",
    "\n",
    "netDict = {0:'HIP', 1:'Poisson', 2:'RSA', 3:'Stealthy0.20', 4:'Stealthy0.40',5:'Stealthy0.49',6:\"Gaussian\"}\n",
    "netNameDict = {0:'HIP', 1:'Poisson', 2:'RSA', 3:'Stealthy0.20', 4:'Stealthy0.40',5:'Stealthy0.49',6:\"Non-stealthy Hyperuniform\"}\n",
    "netType = \"delaunay\"\n",
    "#Real Inputs\n",
    "#measDists = np.arange(0.01,0.5,0.001)\n",
    "\n",
    "#Test Inputs\n",
    "measDists = [0.1,0.11]\n",
    "for netNum in [0]:#range(1):\n",
    "    print(netDict[netNum])\n",
    "    if(netNum == 1):\n",
    "        #numTopos = 6\n",
    "        numTopos = 1\n",
    "    else:\n",
    "        #numTopos = 10\n",
    "        numTopos = 1\n",
    "       \n",
    "    eucSumRes = [[] for _ in range(len(measDists))]\n",
    "    netSumRes = [[] for _ in range(len(measDists))]\n",
    "    eucXsRes = [[] for _ in range(len(measDists))]\n",
    "    eucYsRes = [[] for _ in range(len(measDists))]\n",
    "    netXsRes = [[] for _ in range(len(measDists))]\n",
    "    netYsRes = [[] for _ in range(len(measDists))]\n",
    "    \n",
    "    for topoNum in range(numTopos):\n",
    "        res = getResults(topoNum)\n",
    "        for m in range(len(measDists)):\n",
    "            eucSumRes[m] += res[0][m]\n",
    "            netSumRes[ri][m] += res[1][m]\n",
    "            if(m != len(measDists)-1):\n",
    "                eucXsRes[m] += res[2][m]\n",
    "                eucYsRes[m] += res[3][m]\n",
    "                netXsRes[ri][m] += res[4][m]\n",
    "                netYsRes[ri][m] += res[5][m]\n",
    "                \n",
    "    corrs = []\n",
    "    for m in range(len(measDists)):\n",
    "        corrs.append(sp.pearsonr(eucSumRes[m],netSumRes[m])[0])\n",
    "    correlationResDF = pd.DataFrame(corrs,columns=measDists)\n",
    "    \n",
    "    covarianceResDF = pd.DataFrame(columns=measDists)\n",
    "    covs = []\n",
    "    netCovs = []\n",
    "    for m in range(len(measDists)):\n",
    "        if(len(eucXsRes[m])>2):\n",
    "            covs.append(sp.pearsonr(eucXsRes[m],eucYsRes[m])[0])\n",
    "        else:\n",
    "            covs.append(np.nan)\n",
    "        if(len(netXsRes[R][m])>2):\n",
    "            netCovs.append(sp.pearsonr(netXsRes[R][m],netYsRes[R][m])[0])\n",
    "        else:\n",
    "            netCovs.append(np.nan)\n",
    "    covarianceResDF.loc[\"Euclidean\"] = covs\n",
    "    covarianceResDF.loc[\"Network\"] = netCovs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
